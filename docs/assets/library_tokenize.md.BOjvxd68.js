import{_ as a,c as e,o as i,ag as s}from"./chunks/framework.8SQNO8WI.js";const c=JSON.parse('{"title":"Function: tokenize()","description":"","frontmatter":{},"headers":[],"relativePath":"library/tokenize.md","filePath":"library/tokenize.md"}'),n={name:"library/tokenize.md"};function r(o,t,h,l,d,p){return i(),e("div",null,[...t[0]||(t[0]=[s('<p><a href="./../">@technobuddha</a> &gt; <a href="./../library.html">library</a> &gt; <a href="./index_programming.html">Programming</a> &gt; <a href="./index_programming_variables.html">Variables</a></p><h1 id="function-tokenize" tabindex="-1">Function: tokenize() <a class="header-anchor" href="#function-tokenize" aria-label="Permalink to &quot;Function: tokenize()&quot;">​</a></h1><div class="language-ts vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">ts</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> tokenize</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> string</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> string</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[];</span></span></code></pre></div><p>Defined in: <a href="https://github.com/technobuddha/library/blob/main/src/tokenize.ts#L14" target="_blank" rel="noreferrer">tokenize.ts:14</a></p><p>Splits the input string into an array of words.</p><h2 id="parameters" tabindex="-1">Parameters <a class="header-anchor" href="#parameters" aria-label="Permalink to &quot;Parameters&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Parameter</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>input</code></td><td><code>string</code></td><td>The string to tokenize.</td></tr></tbody></table><h2 id="returns" tabindex="-1">Returns <a class="header-anchor" href="#returns" aria-label="Permalink to &quot;Returns&quot;">​</a></h2><p><code>string</code>[]</p><p>An array of words found in the input string. Returns an empty array if no matches are found.</p>',10)])])}const g=a(n,[["render",r]]);export{c as __pageData,g as default};
